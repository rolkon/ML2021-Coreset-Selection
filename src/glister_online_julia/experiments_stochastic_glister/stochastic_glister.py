# -*- coding: utf-8 -*-
"""stochastic_glister.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z_MAqJEdoAsJvZn1uOzJgsDu8KK6dojf
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

import torch
import torch.utils.data as torch_data
from torch.utils.data import DataLoader
from sklearn.metrics import accuracy_score

from train import train

import random
torch.manual_seed(42)
random.seed(42)
np.random.seed(42)

import warnings
warnings.filterwarnings("ignore")

class DNA_DATA(torch_data.Dataset):
    
    def __init__(self, X, y):
        super(DNA_DATA, self).__init__()
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.long) 
    
    def __len__(self):
        return list(self.X.size())[0]
    
    def __getitem__(self, idx):
        return (self.X[idx], self.y[idx])

class TwoLayerNet(torch.nn.Module):
    def __init__(self, input_dim, n_classes):
        super(TwoLayerNet, self).__init__()
        self.linear1 = torch.nn.Linear(input_dim, 20)
        self.linear2 = torch.nn.Linear(20, n_classes)
    
    def forward(self, x, last=False):
        l1scores = torch.nn.functional.relu(self.linear1(x))
        scores = self.linear2(l1scores)
        if last:
            return scores, l1scores
        else:
            return scores

def random_comparison(epochs, fullset, testset, r, input_dim, n_classes):
  random_samp_loader = DataLoader(random.sample(list(fullset), r), batch_size=20, shuffle=True)
  test_loader = DataLoader(testset, batch_size=50, shuffle=False)
  net = TwoLayerNet(input_dim, n_classes=n_classes)
  criterion = torch.nn.CrossEntropyLoss()
  optimizer = torch.optim.SGD(net.parameters(), lr=0.05)
  train(200, net, criterion, optimizer, random_samp_loader, test_loader, verbose=True)

#----------EXPERIMENTAL SETTING-------------------------------------
#----------DNA DATA SET---------------------------------------------
#----------GLISTER_ONLINE: STOCHASTIC VERSION, NO REGULARIZATION----

data = pd.read_csv('dna.csv')
X_train, X_test, y_train, y_test = train_test_split(data.drop('class', axis = 1), data['class'], test_size = 0.3)
y_train = y_train - 1
y_test = y_test - 1

trainset = DNA_DATA(np.array(X_train), np.array(y_train))
valset = DNA_DATA(np.array(X_train), np.array(y_train))
testset = DNA_DATA(np.array(X_test), np.array(y_test))

print("DNA: stochastic_greedy, no regularization")
from Glister_stochastic_noreg import GlisterOnline

for r in [100, 300, 500]:
  print("\n{fac}% of data set".format(fac=r/10))

  glister = GlisterOnline(
      fullset = trainset,
      valset = valset,
      testset = testset,
      device = "cpu",
      validation_set_fraction = 0.1,
      trn_batch_size = 20,
      val_batch_size = 50,
      tst_batch_size = 50,
      dss_batch_size = 50,
      model = TwoLayerNet(input_dim=180, n_classes=3),
      num_epochs = 20,
      learning_rate = 0.05,
      num_classes = 3,
      n_channels = 1,
      bud = r,
      lam = 0.1,
      r=r)

  val_acc, tst_acc, subtrn_acc, full_trn_acc,\
  val_loss, test_loss, subtrn_loss, full_trn_loss,\
  val_losses, substrn_losses, fulltrn_losses,\
  idxs, time = glister.random_greedy_train_model_online_taylor(np.arange(20))

  print("\nRandom comparison:")

  random_comparison(200, trainset, testset, r, 180, 3)

print("\nFull train:")

full_loader = DataLoader(trainset, batch_size=20, shuffle=True)
test_loader = DataLoader(testset, batch_size=50, shuffle=False)

net = TwoLayerNet(input_dim=180, n_classes=3)
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(net.parameters(), lr=0.05)
train(200, net, criterion, optimizer, full_loader, test_loader, verbose=True)

#----------GLISTER_ONLINE: STOCHASTIC VERSION, REGULARIZATION----

print("\nDNA: stochastic_greedy, regularization")
from Glister_stochastic import GlisterOnline

for r in [100, 300, 500]:
  print("\n{fac}% of data set".format(fac=r/10))

  glister = GlisterOnline(
      fullset = trainset,
      valset = valset,
      testset = testset,
      device = "cpu",
      validation_set_fraction = 0.1,
      trn_batch_size = 20,
      val_batch_size = 50,
      tst_batch_size = 50,
      dss_batch_size = 50,
      model = TwoLayerNet(input_dim=180, n_classes=3),
      num_epochs = 20,
      learning_rate = 0.05,
      num_classes = 3,
      n_channels = 1,
      bud = r,
      lam = 0.1,
      r=r)

  val_acc, tst_acc, subtrn_acc, full_trn_acc,\
  val_loss, test_loss, subtrn_loss, full_trn_loss,\
  val_losses, substrn_losses, fulltrn_losses,\
  idxs, time = glister.random_greedy_train_model_online_taylor(np.arange(20))

  print("\nRandom comparison:")

  random_comparison(200, trainset, testset, r, 180, 3)

print("\nFull train:")

full_loader = DataLoader(trainset, batch_size=20, shuffle=True)
test_loader = DataLoader(testset, batch_size=50, shuffle=False)

net = TwoLayerNet(input_dim=180, n_classes=3)
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(net.parameters(), lr=0.05)
train(200, net, criterion, optimizer, full_loader, test_loader, verbose=True)

from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split


digits, targets = load_digits(return_X_y=True)
digits = digits.astype(np.float32) / 255   # scaling

digits_train, digits_test, targets_train, targets_test = train_test_split(digits, targets, random_state=0)

train_digits = DNA_DATA(digits_train, targets_train)
val_digits = DNA_DATA(digits_train, targets_train)
test_digits = DNA_DATA(digits_test, targets_test)

#----------EXPERIMENTAL SETTING------------------------------------
#----------DIGITS DATA SET---------------------------------------------
#----------GLISTER_ONLINE: STOCHASTIC VERSION, NO REGULARIZATION----

print("SKLEARN DIGITS: stochastic_greedy, no regularization")
from Glister_stochastic_noreg import GlisterOnline
#from GlisterImage import GlisterOnlineImage

for r in [100, 300, 500]:
  print("\n{fac}% of data set".format(fac=r/10))

  glister = GlisterOnline(
      fullset = train_digits,
      valset = val_digits,
      testset = test_digits,
      device = "cpu",
      validation_set_fraction = 0.1,
      trn_batch_size = 20,
      val_batch_size = 50,
      tst_batch_size = 50,
      dss_batch_size = 50,
      model = TwoLayerNet(input_dim=64, n_classes=10),
      num_epochs = 200,
      learning_rate = 0.05,
      num_classes = 10,
      n_channels = 1,
      bud = r,
      lam = 0.1)

  val_acc, tst_acc, subtrn_acc, full_trn_acc,\
  val_loss, test_loss, subtrn_loss, full_trn_loss,\
  val_losses, substrn_losses, fulltrn_losses,\
  idxs, time = glister.random_greedy_train_model_online_taylor(np.arange(20))

  print("\nRandom comparison:")

  random_comparison(200, train_digits, test_digits, r, 64, 10)

print("\nFull train:")

train_loader = DataLoader(train_digits, batch_size=20, shuffle=True)
test_loader = DataLoader(test_digits, batch_size=50, shuffle=False)

net = TwoLayerNet(input_dim=64, n_classes=10)
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(net.parameters(), lr=0.05)
train(200, net, criterion, optimizer, train_loader, test_loader, verbose=True)

#----------GLISTER_ONLINE: STOCHASTIC VERSION, REGULARIZATION----

print("\nSKLEARN DIGITS: stochastic_greedy, regularization")
from Glister_stochastic import GlisterOnline

for r in [100, 300, 500]:
  print("\n{fac}% of data set".format(fac=r/10))

  glister = GlisterOnline(
      fullset = train_digits,
      valset = val_digits,
      testset = test_digits,
      device = "cpu",
      validation_set_fraction = 0.1,
      trn_batch_size = 20,
      val_batch_size = 50,
      tst_batch_size = 50,
      dss_batch_size = 50,
      model = TwoLayerNet(input_dim=64, n_classes=10),
      num_epochs = 200,
      learning_rate = 0.05,
      num_classes = 10,
      n_channels = 1,
      bud = r,
      lam = 0.1)

  val_acc, tst_acc, subtrn_acc, full_trn_acc,\
  val_loss, test_loss, subtrn_loss, full_trn_loss,\
  val_losses, substrn_losses, fulltrn_losses,\
  idxs, time = glister.random_greedy_train_model_online_taylor(np.arange(20))

  print("\nRandom comparison:")

  random_comparison(200, train_digits, test_digits, r, 64, 10)

print("\nFull train:")

full_loader = DataLoader(train_digits, batch_size=20, shuffle=True)
test_loader = DataLoader(test_digits, batch_size=50, shuffle=False)

net = TwoLayerNet(input_dim=64, n_classes=10)
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(net.parameters(), lr=0.05)
train(200, net, criterion, optimizer, full_loader, test_loader, verbose=True)