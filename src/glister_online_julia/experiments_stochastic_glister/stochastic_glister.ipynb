{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "stochastic_glister.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "understanding-quest"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.utils.data as torch_data\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from train import train\n",
        "\n",
        "import random\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "id": "understanding-quest",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "superb-advancement"
      },
      "source": [
        "class DNA_DATA(torch_data.Dataset):\n",
        "    \n",
        "    def __init__(self, X, y):\n",
        "        super(DNA_DATA, self).__init__()\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.long) \n",
        "    \n",
        "    def __len__(self):\n",
        "        return list(self.X.size())[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return (self.X[idx], self.y[idx])"
      ],
      "id": "superb-advancement",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pursuant-lexington"
      },
      "source": [
        "class TwoLayerNet(torch.nn.Module):\n",
        "    def __init__(self, input_dim, n_classes):\n",
        "        super(TwoLayerNet, self).__init__()\n",
        "        self.linear1 = torch.nn.Linear(input_dim, 20)\n",
        "        self.linear2 = torch.nn.Linear(20, n_classes)\n",
        "    \n",
        "    def forward(self, x, last=False):\n",
        "        l1scores = torch.nn.functional.relu(self.linear1(x))\n",
        "        scores = self.linear2(l1scores)\n",
        "        if last:\n",
        "            return scores, l1scores\n",
        "        else:\n",
        "            return scores"
      ],
      "id": "pursuant-lexington",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDhj7OfZ4u7I"
      },
      "source": [
        "def random_comparison(epochs, fullset, testset, r, input_dim, n_classes):\n",
        "  random_samp_loader = DataLoader(random.sample(list(fullset), r), batch_size=20, shuffle=True)\n",
        "  test_loader = DataLoader(testset, batch_size=50, shuffle=False)\n",
        "  net = TwoLayerNet(input_dim, n_classes=n_classes)\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(net.parameters(), lr=0.05)\n",
        "  train(200, net, criterion, optimizer, random_samp_loader, test_loader, verbose=True)"
      ],
      "id": "zDhj7OfZ4u7I",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gy9ar0tQaeng",
        "outputId": "f036d1f9-b61a-4639-d3ac-e2aaf77cb574"
      },
      "source": [
        "#----------EXPERIMENTAL SETTING-------------------------------------\n",
        "#----------DNA DATA SET---------------------------------------------\n",
        "#----------GLISTER_ONLINE: STOCHASTIC VERSION, NO REGULARIZATION----\n",
        "\n",
        "data = pd.read_csv('dna.csv')\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop('class', axis = 1), data['class'], test_size = 0.3)\n",
        "y_train = y_train - 1\n",
        "y_test = y_test - 1\n",
        "\n",
        "trainset = DNA_DATA(np.array(X_train), np.array(y_train))\n",
        "valset = DNA_DATA(np.array(X_train), np.array(y_train))\n",
        "testset = DNA_DATA(np.array(X_test), np.array(y_test))\n",
        "\n",
        "print(\"DNA: stochastic_greedy, no regularization\")\n",
        "from Glister_stochastic_noreg import GlisterOnline\n",
        "\n",
        "for r in [100, 300, 500]:\n",
        "  print(\"\\n{fac}% of data set\".format(fac=r/10))\n",
        "\n",
        "  glister = GlisterOnline(\n",
        "      fullset = trainset,\n",
        "      valset = valset,\n",
        "      testset = testset,\n",
        "      device = \"cpu\",\n",
        "      validation_set_fraction = 0.1,\n",
        "      trn_batch_size = 20,\n",
        "      val_batch_size = 50,\n",
        "      tst_batch_size = 50,\n",
        "      dss_batch_size = 50,\n",
        "      model = TwoLayerNet(input_dim=180, n_classes=3),\n",
        "      num_epochs = 20,\n",
        "      learning_rate = 0.05,\n",
        "      num_classes = 3,\n",
        "      n_channels = 1,\n",
        "      bud = r,\n",
        "      lam = 0.1,\n",
        "      r=r)\n",
        "\n",
        "  val_acc, tst_acc, subtrn_acc, full_trn_acc,\\\n",
        "  val_loss, test_loss, subtrn_loss, full_trn_loss,\\\n",
        "  val_losses, substrn_losses, fulltrn_losses,\\\n",
        "  idxs, time = glister.random_greedy_train_model_online_taylor(np.arange(20))\n",
        "\n",
        "  print(\"\\nRandom comparison:\")\n",
        "\n",
        "  random_comparison(200, trainset, testset, r, 180, 3)\n",
        "\n",
        "print(\"\\nFull train:\")\n",
        "\n",
        "full_loader = DataLoader(trainset, batch_size=20, shuffle=True)\n",
        "test_loader = DataLoader(testset, batch_size=50, shuffle=False)\n",
        "\n",
        "net = TwoLayerNet(input_dim=180, n_classes=3)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.05)\n",
        "train(200, net, criterion, optimizer, full_loader, test_loader, verbose=True)\n",
        "\n",
        "#----------GLISTER_ONLINE: STOCHASTIC VERSION, REGULARIZATION----\n",
        "\n",
        "print(\"\\nDNA: stochastic_greedy, regularization\")\n",
        "from Glister_stochastic import GlisterOnline\n",
        "\n",
        "for r in [100, 300, 500]:\n",
        "  print(\"\\n{fac}% of data set\".format(fac=r/10))\n",
        "\n",
        "  glister = GlisterOnline(\n",
        "      fullset = trainset,\n",
        "      valset = valset,\n",
        "      testset = testset,\n",
        "      device = \"cpu\",\n",
        "      validation_set_fraction = 0.1,\n",
        "      trn_batch_size = 20,\n",
        "      val_batch_size = 50,\n",
        "      tst_batch_size = 50,\n",
        "      dss_batch_size = 50,\n",
        "      model = TwoLayerNet(input_dim=180, n_classes=3),\n",
        "      num_epochs = 20,\n",
        "      learning_rate = 0.05,\n",
        "      num_classes = 3,\n",
        "      n_channels = 1,\n",
        "      bud = r,\n",
        "      lam = 0.1,\n",
        "      r=r)\n",
        "\n",
        "  val_acc, tst_acc, subtrn_acc, full_trn_acc,\\\n",
        "  val_loss, test_loss, subtrn_loss, full_trn_loss,\\\n",
        "  val_losses, substrn_losses, fulltrn_losses,\\\n",
        "  idxs, time = glister.random_greedy_train_model_online_taylor(np.arange(20))\n",
        "\n",
        "  print(\"\\nRandom comparison:\")\n",
        "\n",
        "  random_comparison(200, trainset, testset, r, 180, 3)\n",
        "\n",
        "print(\"\\nFull train:\")\n",
        "\n",
        "full_loader = DataLoader(trainset, batch_size=20, shuffle=True)\n",
        "test_loader = DataLoader(testset, batch_size=50, shuffle=False)\n",
        "\n",
        "net = TwoLayerNet(input_dim=180, n_classes=3)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.05)\n",
        "train(200, net, criterion, optimizer, full_loader, test_loader, verbose=True)"
      ],
      "id": "Gy9ar0tQaeng",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DNA: stochastic_greedy, no regularization\n",
            "\n",
            "10.0% of data set\n",
            "SelectionRun---------------------------------\n",
            "Final SubsetTrn and FullTrn Loss: 2.8617196679115295 66.76037114858627\n",
            "Validation Loss and Accuracy: 3.497330904006958 0.7802690582959642\n",
            "Test Data Loss and Accuracy: 13.518501281738281 0.7740585774058577\n",
            "-----------------------------------\n",
            "\n",
            "Random comparison:\n",
            "Test Data Loss 200 , Loss : 0.00517 , and Accuracy: 0.826\n",
            "\n",
            "30.0% of data set\n",
            "SelectionRun---------------------------------\n",
            "Final SubsetTrn and FullTrn Loss: 3.4522235840559006 27.191657595336437\n",
            "Validation Loss and Accuracy: 1.5143404304981232 0.905829596412556\n",
            "Test Data Loss and Accuracy: 6.316932663321495 0.9037656903765691\n",
            "-----------------------------------\n",
            "\n",
            "Random comparison:\n",
            "Test Data Loss 200 , Loss : 0.00258 , and Accuracy: 0.902\n",
            "\n",
            "50.0% of data set\n",
            "SelectionRun---------------------------------\n",
            "Final SubsetTrn and FullTrn Loss: 4.206054195761681 19.265915852040052\n",
            "Validation Loss and Accuracy: 1.1757498234510422 0.905829596412556\n",
            "Test Data Loss and Accuracy: 4.733356386423111 0.9184100418410042\n",
            "-----------------------------------\n",
            "\n",
            "Random comparison:\n",
            "Test Data Loss 200 , Loss : 0.00196 , and Accuracy: 0.902\n",
            "\n",
            "Full train:\n",
            "Test Data Loss 200 , Loss : 0.00487 , and Accuracy: 0.944\n",
            "\n",
            "DNA: stochastic_greedy, regularization\n",
            "\n",
            "10.0% of data set\n",
            "SelectionRun---------------------------------\n",
            "Final SubsetTrn and FullTrn Loss: 6.550105035305023 53.2840838432312\n",
            "Validation Loss and Accuracy: 2.7467339038848877 0.905829596412556\n",
            "Test Data Loss and Accuracy: 10.952403217554092 0.897489539748954\n",
            "-----------------------------------\n",
            "\n",
            "Random comparison:\n",
            "Test Data Loss 200 , Loss : 0.00476 , and Accuracy: 0.806\n",
            "\n",
            "30.0% of data set\n",
            "SelectionRun---------------------------------\n",
            "Final SubsetTrn and FullTrn Loss: 5.929385997354984 10.059775618836284\n",
            "Validation Loss and Accuracy: 1.1140506863594055 0.9461883408071748\n",
            "Test Data Loss and Accuracy: 3.3562929332256317 0.9571129707112971\n",
            "-----------------------------------\n",
            "\n",
            "Random comparison:\n",
            "Test Data Loss 200 , Loss : 0.00262 , and Accuracy: 0.869\n",
            "\n",
            "50.0% of data set\n",
            "SelectionRun---------------------------------\n",
            "Final SubsetTrn and FullTrn Loss: 5.5758186429739 6.6551236333325505\n",
            "Validation Loss and Accuracy: 0.5398392528295517 0.9551569506726457\n",
            "Test Data Loss and Accuracy: 2.8343770541250706 0.9550209205020921\n",
            "-----------------------------------\n",
            "\n",
            "Random comparison:\n",
            "Test Data Loss 200 , Loss : 0.00188 , and Accuracy: 0.896\n",
            "\n",
            "Full train:\n",
            "Test Data Loss 200 , Loss : 0.00412 , and Accuracy: 0.947\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAiQI4-Taes7"
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "digits, targets = load_digits(return_X_y=True)\n",
        "digits = digits.astype(np.float32) / 255   # scaling\n",
        "\n",
        "digits_train, digits_test, targets_train, targets_test = train_test_split(digits, targets, random_state=0)\n",
        "\n",
        "train_digits = DNA_DATA(digits_train, targets_train)\n",
        "val_digits = DNA_DATA(digits_train, targets_train)\n",
        "test_digits = DNA_DATA(digits_test, targets_test)"
      ],
      "id": "BAiQI4-Taes7",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uczJJdFiaevg",
        "outputId": "13fb9634-38ca-48c7-bdff-bb624cd21e9b"
      },
      "source": [
        "#----------EXPERIMENTAL SETTING------------------------------------\n",
        "#----------DIGITS DATA SET---------------------------------------------\n",
        "#----------GLISTER_ONLINE: STOCHASTIC VERSION, NO REGULARIZATION----\n",
        "\n",
        "print(\"SKLEARN DIGITS: stochastic_greedy, no regularization\")\n",
        "from Glister_stochastic_noreg import GlisterOnline\n",
        "#from GlisterImage import GlisterOnlineImage\n",
        "\n",
        "for r in [100, 300, 500]:\n",
        "  print(\"\\n{fac}% of data set\".format(fac=r/10))\n",
        "\n",
        "  glister = GlisterOnline(\n",
        "      fullset = train_digits,\n",
        "      valset = val_digits,\n",
        "      testset = test_digits,\n",
        "      device = \"cpu\",\n",
        "      validation_set_fraction = 0.1,\n",
        "      trn_batch_size = 20,\n",
        "      val_batch_size = 50,\n",
        "      tst_batch_size = 50,\n",
        "      dss_batch_size = 50,\n",
        "      model = TwoLayerNet(input_dim=64, n_classes=10),\n",
        "      num_epochs = 200,\n",
        "      learning_rate = 0.05,\n",
        "      num_classes = 10,\n",
        "      n_channels = 1,\n",
        "      bud = r,\n",
        "      lam = 0.1)\n",
        "\n",
        "  val_acc, tst_acc, subtrn_acc, full_trn_acc,\\\n",
        "  val_loss, test_loss, subtrn_loss, full_trn_loss,\\\n",
        "  val_losses, substrn_losses, fulltrn_losses,\\\n",
        "  idxs, time = glister.random_greedy_train_model_online_taylor(np.arange(20))\n",
        "\n",
        "  print(\"\\nRandom comparison:\")\n",
        "\n",
        "  random_comparison(200, train_digits, test_digits, r, 64, 10)\n",
        "\n",
        "print(\"\\nFull train:\")\n",
        "\n",
        "train_loader = DataLoader(train_digits, batch_size=20, shuffle=True)\n",
        "test_loader = DataLoader(test_digits, batch_size=50, shuffle=False)\n",
        "\n",
        "net = TwoLayerNet(input_dim=64, n_classes=10)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.05)\n",
        "train(200, net, criterion, optimizer, train_loader, test_loader, verbose=True)\n",
        "\n",
        "#----------GLISTER_ONLINE: STOCHASTIC VERSION, REGULARIZATION----\n",
        "\n",
        "print(\"\\nSKLEARN DIGITS: stochastic_greedy, regularization\")\n",
        "from Glister_stochastic import GlisterOnline\n",
        "\n",
        "for r in [100, 300, 500]:\n",
        "  print(\"\\n{fac}% of data set\".format(fac=r/10))\n",
        "\n",
        "  glister = GlisterOnline(\n",
        "      fullset = train_digits,\n",
        "      valset = val_digits,\n",
        "      testset = test_digits,\n",
        "      device = \"cpu\",\n",
        "      validation_set_fraction = 0.1,\n",
        "      trn_batch_size = 20,\n",
        "      val_batch_size = 50,\n",
        "      tst_batch_size = 50,\n",
        "      dss_batch_size = 50,\n",
        "      model = TwoLayerNet(input_dim=64, n_classes=10),\n",
        "      num_epochs = 200,\n",
        "      learning_rate = 0.05,\n",
        "      num_classes = 10,\n",
        "      n_channels = 1,\n",
        "      bud = r,\n",
        "      lam = 0.1)\n",
        "\n",
        "  val_acc, tst_acc, subtrn_acc, full_trn_acc,\\\n",
        "  val_loss, test_loss, subtrn_loss, full_trn_loss,\\\n",
        "  val_losses, substrn_losses, fulltrn_losses,\\\n",
        "  idxs, time = glister.random_greedy_train_model_online_taylor(np.arange(20))\n",
        "\n",
        "  print(\"\\nRandom comparison:\")\n",
        "\n",
        "  random_comparison(200, train_digits, test_digits, r, 64, 10)\n",
        "\n",
        "print(\"\\nFull train:\")\n",
        "\n",
        "full_loader = DataLoader(train_digits, batch_size=20, shuffle=True)\n",
        "test_loader = DataLoader(test_digits, batch_size=50, shuffle=False)\n",
        "\n",
        "net = TwoLayerNet(input_dim=64, n_classes=10)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.05)\n",
        "train(200, net, criterion, optimizer, full_loader, test_loader, verbose=True)"
      ],
      "id": "uczJJdFiaevg",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SKLEARN DIGITS: stochastic_greedy, no regularization\n",
            "\n",
            "10.0% of data set\n",
            "SelectionRun---------------------------------\n",
            "Final SubsetTrn and FullTrn Loss: 11.325555801391602 140.52311849594116\n",
            "Validation Loss and Accuracy: 6.799923896789551 0.1417910447761194\n",
            "Test Data Loss and Accuracy: 20.777456045150757 0.10666666666666667\n",
            "-----------------------------------\n",
            "\n",
            "Random comparison:\n",
            "Test Data Loss 200 , Loss : 2.26 , and Accuracy: 0.0956\n",
            "\n",
            "30.0% of data set\n",
            "SelectionRun---------------------------------\n",
            "Final SubsetTrn and FullTrn Loss: 31.620559453964233 130.3787670135498\n",
            "Validation Loss and Accuracy: 6.331751585006714 0.44029850746268656\n",
            "Test Data Loss and Accuracy: 19.37464427947998 0.37777777777777777\n",
            "-----------------------------------\n",
            "\n",
            "Random comparison:\n",
            "Test Data Loss 200 , Loss : 2.16 , and Accuracy: 0.18\n",
            "\n",
            "50.0% of data set\n",
            "SelectionRun---------------------------------\n",
            "Final SubsetTrn and FullTrn Loss: 36.83873927593231 97.02149260044098\n",
            "Validation Loss and Accuracy: 4.584716796875 0.6716417910447762\n",
            "Test Data Loss and Accuracy: 14.691855549812317 0.5688888888888889\n",
            "-----------------------------------\n",
            "\n",
            "Random comparison:\n",
            "Test Data Loss 200 , Loss : 1.54 , and Accuracy: 0.629\n",
            "\n",
            "Full train:\n",
            "Test Data Loss 200 , Loss : 0.393 , and Accuracy: 0.902\n",
            "\n",
            "SKLEARN DIGITS: stochastic_greedy, regularization\n",
            "\n",
            "10.0% of data set\n",
            "SelectionRun---------------------------------\n",
            "Final SubsetTrn and FullTrn Loss: 22.150275230407715 139.7611312866211\n",
            "Validation Loss and Accuracy: 6.6518027782440186 0.27611940298507465\n",
            "Test Data Loss and Accuracy: 20.750258922576904 0.17333333333333334\n",
            "-----------------------------------\n",
            "\n",
            "Random comparison:\n",
            "Test Data Loss 200 , Loss : 2.24 , and Accuracy: 0.191\n",
            "\n",
            "30.0% of data set\n",
            "SelectionRun---------------------------------\n",
            "Final SubsetTrn and FullTrn Loss: 39.99473249912262 87.87453615665436\n",
            "Validation Loss and Accuracy: 4.156734347343445 0.6268656716417911\n",
            "Test Data Loss and Accuracy: 13.395251154899597 0.5288888888888889\n",
            "-----------------------------------\n",
            "\n",
            "Random comparison:\n",
            "Test Data Loss 200 , Loss : 2.13 , and Accuracy: 0.289\n",
            "\n",
            "50.0% of data set\n",
            "SelectionRun---------------------------------\n",
            "Final SubsetTrn and FullTrn Loss: 27.375744998455048 33.84084188938141\n",
            "Validation Loss and Accuracy: 1.7877490520477295 0.8283582089552238\n",
            "Test Data Loss and Accuracy: 5.271835118532181 0.8622222222222222\n",
            "-----------------------------------\n",
            "\n",
            "Random comparison:\n",
            "Test Data Loss 200 , Loss : 1.63 , and Accuracy: 0.627\n",
            "\n",
            "Full train:\n",
            "Test Data Loss 200 , Loss : 0.368 , and Accuracy: 0.907\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}